# Building Contour Detection and Height Estimation Problem

This project contains the provided solution for the 5th place (5750901 test score) in the Algotester ML contest 2024 (https://algotester.com/mlc/en)
This repository serves as the report describing the solution and covering the following elements:

- general description of the idea behind your best result
- models and tools used to produce your result
- the source code with enhanced comments explaining how it works
- ideas on how your approach can be improved


## General description of the approach

As the task demands detecting the contours of the building and estimating the height, I naturally split the algorithm into two consecutive parts, where the first part covers the contour
detection and the second part height estimation.

### First part - contour estimation

Given the annotation for approx. 2000 images, I decided to formulate the problem as the binary segmentation problem, which is quite natural given the fact that we can easily
convert the original labelme annotations into binary segmentation masks. I experimented with different architectures (Unet, Manet, Deeplabv3), encoder architectures and their size, loss functions, data augmentations, and training hyperparameters (optimizer, batch size, learning rate schedule, etc.).
I split the original data into train and validation and selected the results on the basis of the estimated score (using scorer.py) on the validation set (80% to 20% split)

**My key findings in part 1) are the following  are**:

Attention-based architectures performs slightly better than FCN networks
Mixed Visual Transformer showed the best results as the choice for the encoder in the segmentation network (selecting networks with more than 50mln parameters doesn't seem to increase the score by a significant margin)
Batch size matters (larger batch size provides higher scores on the validation set under  the constant learning rate)
Jaccard loss outperforms other losses by a large margin
Hard data augmentations (linear transformations + color transformation and + elastic transformations) improve the score (which is logical as the amount of training data is quite small)

Best result was provided by the following configurations:

- Manet segmentation network with mixed visual transformer (44mln parameters) encoder pre-trained on Imagenet.
- Batch size - 16
- The constant learning rate of - 0.00001 
- Optimizer - Adam
- Hard data augmentations
- Predicted mask post-processing into the labelme format - cv2.findCountours + cv2.approxpolydp

### Second part - height estimation

I decided to estimate height similarly to how I solved the contour extraction part. I decided to use a Unet-based architecture that outputs a mask with the height values for each pixel of the input image.
Though, as the input I pass not only the original image, but also the mask that was generated by the network from part 1) (adding the mask as the fourth channel). The assumption is that the model won't need to extract the 
contours (as they are already given by the mask as the input) and will only learn to estimate the height. After obtaining the output mask, I average the value of elements that correspond to connected regions (separate buildings) 
and assign this averaged value as the height of the building. In all experiments, I used MSE loss.

**My key findings in part 2) are the following  are**:

- Model architecture doesn't seem to affect the result significantly (or the selection of the encoder)
- Larger models provided better scores (I haven't identified the upper limit at which performance doesn't increase, so I chose the largest model that my resources allowed me to train)
- Data augmentations don't seem to help much (elastic transformations even hurt the performance significantly)
- The more accurate the mask from part 1) is, the better losses can be obtained (that is the bottleneck, as when I passed not the predicted masks but original annotations as the 4 channel input (perfect masks), the loss would drop significantly)

## Tools used to obtain the result:
Python stack (torch, torch-lightning, cv2, skimage, transformers, segmentation-pytorch-models)

The training was performed on NVIDIA GeForce 3090Ti GPU

**train_segmentation.py** training the contour extraction model (the configuration is specified under segmentation/config_seg.yaml)

**train_height.py** training the height estimation model (the configuration is specified under config.yaml)

**inference.py** - getting results for test data


### Ideas how to improve

I think that using SAM (Segment Anything) model in part 1) of my pipeline can be extremely promising. I tried to fine-tune the smallest version of this model and it provided results that
are almost equivalent to my best approach. Unfortunately, I didn't have the computational resources to test a bigger version of this model, but I think it has a huge potential.









